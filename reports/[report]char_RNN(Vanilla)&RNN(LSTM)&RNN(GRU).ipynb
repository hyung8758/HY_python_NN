{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of English character recognition performance among RNN(Vanilla), RNN(LSTM), and RNN(GRU).\n",
    "                                                                                        Hyungwon Yang\n",
    "                                                                                             04.19.17\n",
    "                                                                                            EMCS Labs\n",
    "### Task\n",
    "Tensorflow에서 제공하는 기본적인 RNN방식과 LSTM cell, 그리고 GRU cell을 적용한 RNN방식 총 3가지 모델의 성능을 비교한다.\n",
    "- 영어 character 단위의 데이터셋을 이용하여 훈련한 뒤, 훈련에 사용하지 않은 테스트 셋으로 결과를 추출하여 세 모델의 성능을 비교한다.\n",
    "\n",
    "### Training Corpus\n",
    "- Project Gutenberg's The Divine Comedy, Complete, by Dante Alighieri\n",
    "This eBook is for the use of anyone anywhere at no cost and with almost no restrictions whatsoever. You may copy it, give it away or re-use it under the terms of the Project Gutenberg License included with this eBook or online at www.gutenberg.org\n",
    "The part of the corpus was extracted for training.\n",
    "\n",
    "### Experimental Setting.\n",
    "- Python 3.5.3\n",
    "- Tnesorflow 1.0.0\n",
    "- Mac OSX sierra 10.12.4\n",
    "\n",
    "### Data Preprocessing.\n",
    "- 이전 report에서 보고하였던 것으로 갈음한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN(Vanilla) Training\n",
    "- Epoch는 50, 100, 200으로 총 3번에 걸쳐 실행하였으며, 자세한 설정사항은 아래와 같다.\n",
    "- 설정값\n",
    " 1. 훈련에 사용된 데이터: 8,500 - 20 - 38 (# of examples, # of time steps ,# of input features)\n",
    " 2. 테스트에 사용된 데이터 : 1,650 - 20 - 38 (# of examples, # of time steps ,# of input features)\n",
    " 3. 훈련에 사용되는 데이터중 20%를 validation 셋으로 구성하였다. (1,700개) 이 validation은 epoch가 진행됨에 따라 변화되는 accuracy(인풋 케릭터에 대한 아웃풋 케릭터 결과)를 보여준다.\n",
    " 4. parameters: epoch: 200, 1 hidden layer and its size: [50, 100, 200], learning rate: 0.001, cost function: adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "# HY_python_NN absolute directory.\n",
    "my_absdir = \"/Users/hyungwonyang/Google_Drive/Python/HY_python_NN\"\n",
    "sys.path.append(my_absdir)\n",
    "\n",
    "import numpy as np\n",
    "import main.setvalues as set\n",
    "import main.rnnnetworkmodels as net\n",
    "\n",
    "# import data.\n",
    "# data directory.\n",
    "rnn_data = np.load(my_absdir+'/train_data/pg8800_lstm_char_data.npz')\n",
    "train_input = rnn_data['train_input']\n",
    "train_output = rnn_data['train_output']\n",
    "test_input = rnn_data['test_input']\n",
    "test_output = rnn_data['test_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "problem = 'classification' # classification, regression\n",
    "rnnCell = 'rnn' # rnn, lstm, gru\n",
    "trainEpoch = 20\n",
    "learningRate = 0.001\n",
    "learningRateDecay = 'off' # on, off\n",
    "batchSize = 100\n",
    "hiddenLayers = [200]\n",
    "timeStep = 20\n",
    "costFunction = 'adam' # gradient, adam\n",
    "validationCheck = 'on' # if validationCheck is on, then 20% of train data will be taken for validation.\n",
    "\n",
    "rnn_values = set.simpleRNNParam(inputData=train_input,\n",
    "                           targetData=train_output,\n",
    "                           timeStep=timeStep,\n",
    "                           hiddenUnits=hiddenLayers\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setting hidden layers: weightMatrix and biasMatrix\n",
    "rnn_weightMatrix = rnn_values.genWeight()\n",
    "rnn_biasMatrix = rnn_values.genBias()\n",
    "rnn_input_x,rnn_input_y = rnn_values.genSymbol()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN cell type is rnn\n"
     ]
    }
   ],
   "source": [
    "rnn_net = net.simpleRNNModel(inputSymbol=rnn_input_x,\n",
    "                               outputSymbol=rnn_input_y,\n",
    "                               rnnCell=rnnCell,\n",
    "                               problem=problem,\n",
    "                               trainEpoch=trainEpoch,\n",
    "                               learningRate=learningRate,\n",
    "                               timeStep=timeStep,\n",
    "                               batchSize=batchSize,\n",
    "                               validationCheck=validationCheck,\n",
    "                               weightMatrix=rnn_weightMatrix,\n",
    "                               biasMatrix=rnn_biasMatrix)\n",
    "\n",
    "# Generate a RNN(vanilla) network.\n",
    "rnn_net.genRNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   1 /  20, Cost : 2.976553, Validation Accuracy: 34.87%\n",
      "Epoch:   2 /  20, Cost : 2.278241, Validation Accuracy: 36.48%\n",
      "Epoch:   3 /  20, Cost : 2.201451, Validation Accuracy: 36.69%\n",
      "Epoch:   4 /  20, Cost : 2.170949, Validation Accuracy: 36.81%\n",
      "Epoch:   5 /  20, Cost : 2.154979, Validation Accuracy: 36.87%\n",
      "Epoch:   6 /  20, Cost : 2.144995, Validation Accuracy: 36.76%\n",
      "Epoch:   7 /  20, Cost : 2.138060, Validation Accuracy: 36.83%\n",
      "Epoch:   8 /  20, Cost : 2.132922, Validation Accuracy: 36.82%\n",
      "Epoch:   9 /  20, Cost : 2.128956, Validation Accuracy: 36.80%\n",
      "Epoch:  10 /  20, Cost : 2.125770, Validation Accuracy: 36.81%\n",
      "Epoch:  11 /  20, Cost : 2.123116, Validation Accuracy: 36.83%\n",
      "Epoch:  12 /  20, Cost : 2.120850, Validation Accuracy: 36.80%\n",
      "Epoch:  13 /  20, Cost : 2.118882, Validation Accuracy: 36.80%\n",
      "Epoch:  14 /  20, Cost : 2.117151, Validation Accuracy: 36.81%\n",
      "Epoch:  15 /  20, Cost : 2.115612, Validation Accuracy: 36.86%\n",
      "Epoch:  16 /  20, Cost : 2.114227, Validation Accuracy: 36.87%\n",
      "Epoch:  17 /  20, Cost : 2.112969, Validation Accuracy: 36.89%\n",
      "Epoch:  18 /  20, Cost : 2.111816, Validation Accuracy: 36.84%\n",
      "Epoch:  19 /  20, Cost : 2.110749, Validation Accuracy: 36.80%\n",
      "Epoch:  20 /  20, Cost : 2.109756, Validation Accuracy: 36.81%\n",
      "The model has been trained successfully.\n"
     ]
    }
   ],
   "source": [
    "# Train the RNN(vanilla) network.\n",
    "# In this tutorial, we will run only 20 epochs.\n",
    "rnn_net.trainRNN(train_input,train_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested with 1650 datasets.\n",
      "Test Accuracy: 37.52 %\n"
     ]
    }
   ],
   "source": [
    "# Test the trained RNN(vanilla) network.\n",
    "rnn_net.testRNN(test_input,test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable list as a dictionary format.\n",
      ">> weight, bias, y_hat, optimizer, cost\n",
      "\n",
      "Simple RNN training session is terminated.\n"
     ]
    }
   ],
   "source": [
    "# Save the trained parameters.\n",
    "vars = rnn_net.getVariables()\n",
    "# Terminate the session.\n",
    "rnn_net.closeRNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN(LSTM) Training\n",
    "- Epoch는 50, 100, 200으로 총 3번에 걸쳐 실행하였으며, 자세한 설정사항은 아래와 같다.\n",
    "- 설정값\n",
    " 1. 훈련에 사용된 데이터: 8,500 - 20 - 38 (# of examples, # of time steps ,# of input features)\n",
    " 2. 테스트에 사용된 데이터 : 1,650 - 20 - 38 (# of examples, # of time steps ,# of input features)\n",
    " 3. 훈련에 사용되는 데이터중 20%를 validation 셋으로 구성하였다. (1,700개) 이 validation은 epoch가 진행됨에 따라 변화되는 accuracy(인풋 케릭터에 대한 아웃풋 케릭터 결과)를 보여준다.\n",
    " 4. parameters: epoch: 200, 1 hidden layer and its size: [50, 100, 200], learning rate: 0.001, cost function: adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import main.setvalues as set\n",
    "import main.rnnnetworkmodels as net\n",
    "\n",
    "# import data.\n",
    "# data directory.\n",
    "lstm_data = np.load(my_absdir+'/train_data/pg8800_lstm_char_data.npz')\n",
    "train_input = lstm_data['train_input']\n",
    "train_output = lstm_data['train_output']\n",
    "test_input = lstm_data['test_input']\n",
    "test_output = lstm_data['test_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "problem = 'classification' # classification, regression\n",
    "rnnCell = 'lstm' # rnn, lstm, gru\n",
    "trainEpoch = 20\n",
    "learningRate = 0.001\n",
    "learningRateDecay = 'off' # on, off\n",
    "batchSize = 100\n",
    "hiddenLayers = [200]\n",
    "timeStep = 20\n",
    "costFunction = 'adam' # gradient, adam\n",
    "validationCheck = 'on' # if validationCheck is on, then 20% of train data will be taken for validation.\n",
    "\n",
    "lstm_values = set.simpleRNNParam(inputData=train_input,\n",
    "                           targetData=train_output,\n",
    "                           timeStep=timeStep,\n",
    "                           hiddenUnits=hiddenLayers\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setting hidden layers: weightMatrix and biasMatrix\n",
    "lstm_weightMatrix = lstm_values.genWeight()\n",
    "lstm_biasMatrix = lstm_values.genBias()\n",
    "lstm_input_x,lstm_input_y = lstm_values.genSymbol()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN cell type is lstm\n"
     ]
    }
   ],
   "source": [
    "lstm_net = net.simpleRNNModel(inputSymbol=lstm_input_x,\n",
    "                               outputSymbol=lstm_input_y,\n",
    "                               rnnCell=rnnCell,\n",
    "                               problem=problem,\n",
    "                               trainEpoch=trainEpoch,\n",
    "                               learningRate=learningRate,\n",
    "                               timeStep=timeStep,\n",
    "                               batchSize=batchSize,\n",
    "                               validationCheck=validationCheck,\n",
    "                               weightMatrix=lstm_weightMatrix,\n",
    "                               biasMatrix=lstm_biasMatrix)\n",
    "\n",
    "# Generate a RNN(lstm) network.\n",
    "lstm_net.genRNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   1 /  20, Cost : 3.005780, Validation Accuracy: 27.94%\n",
      "Epoch:   2 /  20, Cost : 2.485927, Validation Accuracy: 32.40%\n",
      "Epoch:   3 /  20, Cost : 2.321439, Validation Accuracy: 34.59%\n",
      "Epoch:   4 /  20, Cost : 2.244965, Validation Accuracy: 35.78%\n",
      "Epoch:   5 /  20, Cost : 2.196952, Validation Accuracy: 36.44%\n",
      "Epoch:   6 /  20, Cost : 2.157184, Validation Accuracy: 37.47%\n",
      "Epoch:   7 /  20, Cost : 2.120310, Validation Accuracy: 38.21%\n",
      "Epoch:   8 /  20, Cost : 2.086483, Validation Accuracy: 38.94%\n",
      "Epoch:   9 /  20, Cost : 2.054665, Validation Accuracy: 39.56%\n",
      "Epoch:  10 /  20, Cost : 2.025842, Validation Accuracy: 40.10%\n",
      "Epoch:  11 /  20, Cost : 1.999812, Validation Accuracy: 40.67%\n",
      "Epoch:  12 /  20, Cost : 1.975952, Validation Accuracy: 41.18%\n",
      "Epoch:  13 /  20, Cost : 1.953950, Validation Accuracy: 41.75%\n",
      "Epoch:  14 /  20, Cost : 1.933704, Validation Accuracy: 42.25%\n",
      "Epoch:  15 /  20, Cost : 1.915146, Validation Accuracy: 42.62%\n",
      "Epoch:  16 /  20, Cost : 1.897975, Validation Accuracy: 42.90%\n",
      "Epoch:  17 /  20, Cost : 1.881300, Validation Accuracy: 43.11%\n",
      "Epoch:  18 /  20, Cost : 1.864792, Validation Accuracy: 43.29%\n",
      "Epoch:  19 /  20, Cost : 1.849229, Validation Accuracy: 43.52%\n",
      "Epoch:  20 /  20, Cost : 1.834553, Validation Accuracy: 43.72%\n",
      "The model has been trained successfully.\n"
     ]
    }
   ],
   "source": [
    "# Train the RNN(lstm) network.\n",
    "# In this tutorial, we will run only 20 epochs.\n",
    "lstm_net.trainRNN(train_input,train_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested with 1650 datasets.\n",
      "Test Accuracy: 45.88 %\n"
     ]
    }
   ],
   "source": [
    "# Test the trained RNN(lstm) network.\n",
    "lstm_net.testRNN(test_input,test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable list as a dictionary format.\n",
      ">> weight, bias, y_hat, optimizer, cost\n",
      "\n",
      "Simple RNN training session is terminated.\n"
     ]
    }
   ],
   "source": [
    "# Save the trained parameters.\n",
    "vars = lstm_net.getVariables()\n",
    "# Terminate the session.\n",
    "lstm_net.closeRNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN(GRU) Training\n",
    "- Epoch는 50, 100, 200으로 총 3번에 걸쳐 실행하였으며, 자세한 설정사항은 아래와 같다.\n",
    "- 설정값\n",
    " 1. 훈련에 사용된 데이터: 8,500 - 20 - 38 (# of examples, # of time steps ,# of input features)\n",
    " 2. 테스트에 사용된 데이터 : 1,650 - 20 - 38 (# of examples, # of time steps ,# of input features)\n",
    " 3. 훈련에 사용되는 데이터중 20%를 validation 셋으로 구성하였다. (1,700개) 이 validation은 epoch가 진행됨에 따라 변화되는 accuracy(인풋 케릭터에 대한 아웃풋 케릭터 결과)를 보여준다.\n",
    " 4. parameters: epoch: 200, 1 hidden layer and its size: [50, 100, 200], learning rate: 0.001, cost function: adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import main.setvalues as set\n",
    "import main.rnnnetworkmodels as net\n",
    "\n",
    "# import data.\n",
    "# data directory.\n",
    "gru_data = np.load(my_absdir+'/train_data/pg8800_lstm_char_data.npz')\n",
    "train_input = gru_data['train_input']\n",
    "train_output = gru_data['train_output']\n",
    "test_input = gru_data['test_input']\n",
    "test_output = gru_data['test_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "problem = 'classification' # classification, regression\n",
    "rnnCell = 'gru' # rnn, lstm, gru\n",
    "trainEpoch = 20\n",
    "learningRate = 0.001\n",
    "learningRateDecay = 'off' # on, off\n",
    "batchSize = 100\n",
    "hiddenLayers = [200]\n",
    "timeStep = 20\n",
    "costFunction = 'adam' # gradient, adam\n",
    "validationCheck = 'on' # if validationCheck is on, then 20% of train data will be taken for validation.\n",
    "\n",
    "gru_values = set.simpleRNNParam(inputData=train_input,\n",
    "                           targetData=train_output,\n",
    "                           timeStep=timeStep,\n",
    "                           hiddenUnits=hiddenLayers\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setting hidden layers: weightMatrix and biasMatrix\n",
    "gru_weightMatrix = gru_values.genWeight()\n",
    "gru_biasMatrix = gru_values.genBias()\n",
    "gru_input_x,gru_input_y = gru_values.genSymbol()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN cell type is gru\n"
     ]
    }
   ],
   "source": [
    "gru_net = net.simpleRNNModel(inputSymbol=gru_input_x,\n",
    "                               outputSymbol=gru_input_y,\n",
    "                               rnnCell=rnnCell,\n",
    "                               problem=problem,\n",
    "                               trainEpoch=trainEpoch,\n",
    "                               learningRate=learningRate,\n",
    "                               timeStep=timeStep,\n",
    "                               batchSize=batchSize,\n",
    "                               validationCheck=validationCheck,\n",
    "                               weightMatrix=gru_weightMatrix,\n",
    "                               biasMatrix=gru_biasMatrix)\n",
    "\n",
    "# Generate a RNN(gru) network.\n",
    "gru_net.genRNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   1 /  20, Cost : 3.025232, Validation Accuracy: 28.73%\n",
      "Epoch:   2 /  20, Cost : 2.452374, Validation Accuracy: 33.44%\n",
      "Epoch:   3 /  20, Cost : 2.276861, Validation Accuracy: 35.94%\n",
      "Epoch:   4 /  20, Cost : 2.192620, Validation Accuracy: 37.06%\n",
      "Epoch:   5 /  20, Cost : 2.135865, Validation Accuracy: 38.27%\n",
      "Epoch:   6 /  20, Cost : 2.089845, Validation Accuracy: 39.01%\n",
      "Epoch:   7 /  20, Cost : 2.049159, Validation Accuracy: 39.80%\n",
      "Epoch:   8 /  20, Cost : 2.012706, Validation Accuracy: 40.52%\n",
      "Epoch:   9 /  20, Cost : 1.979966, Validation Accuracy: 41.10%\n",
      "Epoch:  10 /  20, Cost : 1.950720, Validation Accuracy: 41.75%\n",
      "Epoch:  11 /  20, Cost : 1.924765, Validation Accuracy: 42.33%\n",
      "Epoch:  12 /  20, Cost : 1.901514, Validation Accuracy: 42.74%\n",
      "Epoch:  13 /  20, Cost : 1.880410, Validation Accuracy: 43.10%\n",
      "Epoch:  14 /  20, Cost : 1.861050, Validation Accuracy: 43.48%\n",
      "Epoch:  15 /  20, Cost : 1.843196, Validation Accuracy: 43.82%\n",
      "Epoch:  16 /  20, Cost : 1.826601, Validation Accuracy: 44.07%\n",
      "Epoch:  17 /  20, Cost : 1.811007, Validation Accuracy: 44.39%\n",
      "Epoch:  18 /  20, Cost : 1.796216, Validation Accuracy: 44.70%\n",
      "Epoch:  19 /  20, Cost : 1.782084, Validation Accuracy: 44.91%\n",
      "Epoch:  20 /  20, Cost : 1.768511, Validation Accuracy: 45.09%\n",
      "The model has been trained successfully.\n"
     ]
    }
   ],
   "source": [
    "# Train the RNN(gru) network.\n",
    "# In this tutorial, we will run only 20 epochs.\n",
    "gru_net.trainRNN(train_input,train_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested with 1650 datasets.\n",
      "Test Accuracy: 47.35 %\n"
     ]
    }
   ],
   "source": [
    "# Test the trained RNN(gru) network.\n",
    "gru_net.testRNN(test_input,test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable list as a dictionary format.\n",
      ">> weight, bias, y_hat, optimizer, cost\n",
      "\n",
      "Simple RNN training session is terminated.\n"
     ]
    }
   ],
   "source": [
    "# Save the trained parameters.\n",
    "vars = gru_net.getVariables()\n",
    "# Terminate the session.\n",
    "gru_net.closeRNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments\n",
    "- 위 코드상에서 히든레이어 유닛 개수가 200개인 경우만 한정지어 진행하였으나, 실제로는 히든레이어 유닛 개수를 50, 100, 200으로 달리하여 진행하였으며 그에 따른 결과는 아래의 표에서 나타난다.\n",
    "- 초반 Accuracy의 변화량을 보여주고자 본 코드에서는 각 모델의 훈련 Epoch를 20회만 진행하였으나, 실제 훈련에서는 각 실험당 총 200회의 Epoch가 진행되었다.\n",
    "### Result\n",
    "1. 히든레이어 개수와 상관없이 훈련이 안되던 ANN의 결과와 비교해 볼 때, RNN(Vanilla)와 RNN(LSTM), 그리고 RNN(GRU)는 안정적으로 훈련이 진행되며 그에 따라 성능 향상도 보여주고 있다. \n",
    "2. 표에서 나타나는 것처럼 RNN(LSTM)과 RNN(GRU)가 비슷한 성능을 (히든레이어 유닛 200에서 각각 72.59% 70.89%로 약 2%차이) 보여주며, 이는 RNN(Vanilla) 대비 약 22% 정도의 큰 성능차이를 보여준다.\n",
    "2. RNN(LSTM)과 RNN(GRU)를 놓고 비교해볼 경우 본 실험에서는 RNN(LSTM)이 RNN(Vanilla)보다 약간 2% 정도의 높은 성능을 보여주고 있다. 하지만 최근 논문들에서 GRU가 LSTM보다 더 좋은 결과를 가져온다고 주장하는점으로 비춰 볼 때, 다른 테스크에는 어떤 차이가 나타날지 주목해 볼 필요가 있다.\n",
    "3. 또한 Accuracy 측면에서 RNN(Vanilla)는 불안정하게 하향과 상향을 반복하는 반면, RNN(LSTM)과, RNN(GRU)는 비교적 안정된 Accuracy 상향을 보여주고 있다.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "|       Model    | Hidden Units  | Accuracy     |\n",
    "| :------------: | :-----------: | -----------: |\n",
    "| RNN(Vanilla)   |       50      |     44.42%   |\n",
    "| RNN(Vanilla)   |       100     |     47.86%   |\n",
    "| RNN(Vanilla)   |       200     |     **50.23%**   |\n",
    "| RNN(LSTM)      |       50      |     49.76%   |\n",
    "| RNN(LSTM)      |       100     |     56.54%   |\n",
    "| RNN(LSTM)      |       200     |     **72.59%**   |\n",
    "| RNN(GRU)      |       50      |     49.68%   |\n",
    "| RNN(GRU)      |       100     |     55.75%   |\n",
    "| RNN(GRU)      |       200     |     **70.89%**   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Github Code\n",
    "다음의 깃헙 코드를 다운받으면 본 실험을 재현할 수 있다.\n",
    "- https://github.com/hyung8758/HY_python_NN.git\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
