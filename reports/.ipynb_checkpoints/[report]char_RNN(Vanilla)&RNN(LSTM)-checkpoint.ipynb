{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of English character recognition performance between RNN(Vanilla) and RNN(LSTM).\n",
    "                                                                                        Hyungwon Yang\n",
    "                                                                                             04.19.17\n",
    "                                                                                            EMCS Labs\n",
    "### Task\n",
    "Tensorflow에서 제공하는 기본적인 RNN방식과 LSTM 셀을 적용한 RNN방식 두 모델의 성능을 비교한다.\n",
    "- 영어 character 단위의 데이터셋을 이용하여 훈련한 뒤, 훈련에 사용하지 않은 테스트 셋으로 결과를 추출하여 두 모델의 성능을 비교한다.\n",
    "\n",
    "### Training Corpus\n",
    "Project Gutenberg's The Divine Comedy, Complete, by Dante Alighieri\n",
    "This eBook is for the use of anyone anywhere at no cost and with almost no restrictions whatsoever. You may copy it, give it away or re-use it under the terms of the Project Gutenberg License included with this eBook or online at www.gutenberg.org\n",
    "The part of the corpus was extracted for training.\n",
    "\n",
    "### Experimental Setting.\n",
    "Python 3.5.3\n",
    "Tnesorflow 1.0.0\n",
    "Mac OSX sierra 10.12.4\n",
    "\n",
    "### Data Preprocessing.\n",
    "이전 report1에서 보고하였던 것으로 갈음한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN(Vanilla) Training\n",
    "- Epoch는 50, 100, 200으로 총 3번에 걸쳐 실행하였으며, 자세한 설정사항은 아래와 같다.\n",
    "- 설정값\n",
    " 1. 훈련에 사용된 데이터: 8,500 * 20 * 38 (# of examples, # of time steps ,# of input features)\n",
    " 2. 테스트에 사용된 데이터 : 1,650 * 20 * 38 (# of examples, # of time steps ,# of input features)\n",
    " 3. 훈련에 사용되는 데이터중 20%를 validation 셋으로 구성하였다. (1,700개) 이 validation은 epoch가 진행됨에 따라 변화되는 accuracy(인풋 케릭터에 대한 아웃풋 케릭터 결과)를 보여준다.\n",
    " 4. parameters: epoch: 200, 1 hidden layer and its size: 200, learning rate: 0.001, cost function: adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "# HY_python_NN absolute directory.\n",
    "my_absdir = \"/Users/hyungwonyang/Google_Drive/Python/HY_python_NN\"\n",
    "sys.path.append(my_absdir)\n",
    "\n",
    "import numpy as np\n",
    "import main.setvalues as set\n",
    "import main.rnnnetworkmodels as net\n",
    "\n",
    "# import data.\n",
    "# data directory.\n",
    "rnn_data = np.load(my_absdir+'/train_data/pg8800_lstm_char_data.npz')\n",
    "train_input = rnn_data['train_input']\n",
    "train_output = rnn_data['train_output']\n",
    "test_input = rnn_data['test_input']\n",
    "test_output = rnn_data['test_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "problem = 'classification' # classification, regression\n",
    "rnnCell = 'rnn' # rnn, lstm\n",
    "trainEpoch = 200\n",
    "learningRate = 0.001\n",
    "learningRateDecay = 'off' # on, off\n",
    "batchSize = 100\n",
    "hiddenLayers = [50]\n",
    "timeStep = 20\n",
    "costFunction = 'adam' # gradient, adam\n",
    "validationCheck = 'on' # if validationCheck is on, then 20% of train data will be taken for validation.\n",
    "\n",
    "rnn_values = set.simpleRNNParam(inputData=train_input,\n",
    "                           targetData=train_output,\n",
    "                           timeStep=timeStep,\n",
    "                           hiddenUnits=hiddenLayers\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setting hidden layers: weightMatrix and biasMatrix\n",
    "rnn_weightMatrix = rnn_values.genWeight()\n",
    "rnn_biasMatrix = rnn_values.genBias()\n",
    "rnn_input_x,rnn_input_y = rnn_values.genSymbol()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN cell type is rnn\n"
     ]
    }
   ],
   "source": [
    "rnn_net = net.simpleRNNModel(inputSymbol=rnn_input_x,\n",
    "                               outputSymbol=rnn_input_y,\n",
    "                               rnnCell=rnnCell,\n",
    "                               problem=problem,\n",
    "                               trainEpoch=trainEpoch,\n",
    "                               learningRate=learningRate,\n",
    "                               timeStep=timeStep,\n",
    "                               batchSize=batchSize,\n",
    "                               validationCheck=validationCheck,\n",
    "                               weightMatrix=rnn_weightMatrix,\n",
    "                               biasMatrix=rnn_biasMatrix)\n",
    "\n",
    "# Generate a RNN(lstm) network.\n",
    "rnn_net.genRNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1 / 200 , Cost : 3.124750\n",
      "Validation Accuracy: 31.18 %\n",
      "Epoch : 2 / 200 , Cost : 2.414468\n",
      "Validation Accuracy: 35.52 %\n",
      "Epoch : 3 / 200 , Cost : 2.281629\n",
      "Validation Accuracy: 36.41 %\n",
      "Epoch : 4 / 200 , Cost : 2.225017\n",
      "Validation Accuracy: 36.54 %\n",
      "Epoch : 5 / 200 , Cost : 2.194124\n",
      "Validation Accuracy: 36.75 %\n",
      "Epoch : 6 / 200 , Cost : 2.174914\n",
      "Validation Accuracy: 36.81 %\n",
      "Epoch : 7 / 200 , Cost : 2.161898\n",
      "Validation Accuracy: 36.87 %\n",
      "Epoch : 8 / 200 , Cost : 2.152383\n",
      "Validation Accuracy: 36.97 %\n",
      "Epoch : 9 / 200 , Cost : 2.145038\n",
      "Validation Accuracy: 37.01 %\n",
      "Epoch : 10 / 200 , Cost : 2.139093\n",
      "Validation Accuracy: 37.04 %\n",
      "Epoch : 11 / 200 , Cost : 2.134108\n",
      "Validation Accuracy: 37.14 %\n",
      "Epoch : 12 / 200 , Cost : 2.129818\n",
      "Validation Accuracy: 37.20 %\n",
      "Epoch : 13 / 200 , Cost : 2.126031\n",
      "Validation Accuracy: 37.22 %\n",
      "Epoch : 14 / 200 , Cost : 2.122590\n",
      "Validation Accuracy: 37.30 %\n",
      "Epoch : 15 / 200 , Cost : 2.119373\n",
      "Validation Accuracy: 37.33 %\n",
      "Epoch : 16 / 200 , Cost : 2.116279\n",
      "Validation Accuracy: 37.39 %\n",
      "Epoch : 17 / 200 , Cost : 2.113217\n",
      "Validation Accuracy: 37.50 %\n",
      "Epoch : 18 / 200 , Cost : 2.110108\n",
      "Validation Accuracy: 37.57 %\n",
      "Epoch : 19 / 200 , Cost : 2.106889\n",
      "Validation Accuracy: 37.62 %\n",
      "Epoch : 20 / 200 , Cost : 2.103516\n",
      "Validation Accuracy: 37.68 %\n",
      "Epoch : 21 / 200 , Cost : 2.099972\n",
      "Validation Accuracy: 37.79 %\n",
      "Epoch : 22 / 200 , Cost : 2.096256\n",
      "Validation Accuracy: 37.86 %\n",
      "Epoch : 23 / 200 , Cost : 2.092383\n",
      "Validation Accuracy: 37.95 %\n",
      "Epoch : 24 / 200 , Cost : 2.088374\n",
      "Validation Accuracy: 38.06 %\n",
      "Epoch : 25 / 200 , Cost : 2.084261\n",
      "Validation Accuracy: 38.15 %\n",
      "Epoch : 26 / 200 , Cost : 2.080077\n",
      "Validation Accuracy: 38.31 %\n",
      "Epoch : 27 / 200 , Cost : 2.075850\n",
      "Validation Accuracy: 38.39 %\n",
      "Epoch : 28 / 200 , Cost : 2.071593\n",
      "Validation Accuracy: 38.55 %\n",
      "Epoch : 29 / 200 , Cost : 2.067311\n",
      "Validation Accuracy: 38.75 %\n",
      "Epoch : 30 / 200 , Cost : 2.063011\n",
      "Validation Accuracy: 38.81 %\n",
      "Epoch : 31 / 200 , Cost : 2.058698\n",
      "Validation Accuracy: 38.92 %\n",
      "Epoch : 32 / 200 , Cost : 2.054378\n",
      "Validation Accuracy: 38.97 %\n",
      "Epoch : 33 / 200 , Cost : 2.050059\n",
      "Validation Accuracy: 39.06 %\n",
      "Epoch : 34 / 200 , Cost : 2.045750\n",
      "Validation Accuracy: 39.16 %\n",
      "Epoch : 35 / 200 , Cost : 2.041459\n",
      "Validation Accuracy: 39.33 %\n",
      "Epoch : 36 / 200 , Cost : 2.037194\n",
      "Validation Accuracy: 39.44 %\n",
      "Epoch : 37 / 200 , Cost : 2.032964\n",
      "Validation Accuracy: 39.59 %\n",
      "Epoch : 38 / 200 , Cost : 2.028774\n",
      "Validation Accuracy: 39.67 %\n",
      "Epoch : 39 / 200 , Cost : 2.024627\n",
      "Validation Accuracy: 39.80 %\n",
      "Epoch : 40 / 200 , Cost : 2.020528\n",
      "Validation Accuracy: 39.89 %\n",
      "Epoch : 41 / 200 , Cost : 2.016478\n",
      "Validation Accuracy: 39.97 %\n",
      "Epoch : 42 / 200 , Cost : 2.012479\n",
      "Validation Accuracy: 40.01 %\n",
      "Epoch : 43 / 200 , Cost : 2.008533\n",
      "Validation Accuracy: 40.08 %\n",
      "Epoch : 44 / 200 , Cost : 2.004638\n",
      "Validation Accuracy: 40.11 %\n",
      "Epoch : 45 / 200 , Cost : 2.000795\n",
      "Validation Accuracy: 40.18 %\n",
      "Epoch : 46 / 200 , Cost : 1.997003\n",
      "Validation Accuracy: 40.28 %\n",
      "Epoch : 47 / 200 , Cost : 1.993262\n",
      "Validation Accuracy: 40.37 %\n",
      "Epoch : 48 / 200 , Cost : 1.989569\n",
      "Validation Accuracy: 40.44 %\n",
      "Epoch : 49 / 200 , Cost : 1.985925\n",
      "Validation Accuracy: 40.52 %\n",
      "Epoch : 50 / 200 , Cost : 1.982328\n",
      "Validation Accuracy: 40.59 %\n",
      "Epoch : 51 / 200 , Cost : 1.978777\n",
      "Validation Accuracy: 40.65 %\n",
      "Epoch : 52 / 200 , Cost : 1.975271\n",
      "Validation Accuracy: 40.75 %\n",
      "Epoch : 53 / 200 , Cost : 1.971811\n",
      "Validation Accuracy: 40.83 %\n",
      "Epoch : 54 / 200 , Cost : 1.968395\n",
      "Validation Accuracy: 40.88 %\n",
      "Epoch : 55 / 200 , Cost : 1.965024\n",
      "Validation Accuracy: 40.89 %\n",
      "Epoch : 56 / 200 , Cost : 1.961696\n",
      "Validation Accuracy: 40.96 %\n",
      "Epoch : 57 / 200 , Cost : 1.958412\n",
      "Validation Accuracy: 41.04 %\n",
      "Epoch : 58 / 200 , Cost : 1.955172\n",
      "Validation Accuracy: 41.09 %\n",
      "Epoch : 59 / 200 , Cost : 1.951974\n",
      "Validation Accuracy: 41.14 %\n",
      "Epoch : 60 / 200 , Cost : 1.948818\n",
      "Validation Accuracy: 41.20 %\n",
      "Epoch : 61 / 200 , Cost : 1.945704\n",
      "Validation Accuracy: 41.27 %\n",
      "Epoch : 62 / 200 , Cost : 1.942632\n",
      "Validation Accuracy: 41.31 %\n",
      "Epoch : 63 / 200 , Cost : 1.939600\n",
      "Validation Accuracy: 41.42 %\n",
      "Epoch : 64 / 200 , Cost : 1.936609\n",
      "Validation Accuracy: 41.50 %\n",
      "Epoch : 65 / 200 , Cost : 1.933659\n",
      "Validation Accuracy: 41.59 %\n",
      "Epoch : 66 / 200 , Cost : 1.930750\n",
      "Validation Accuracy: 41.68 %\n",
      "Epoch : 67 / 200 , Cost : 1.927881\n",
      "Validation Accuracy: 41.73 %\n",
      "Epoch : 68 / 200 , Cost : 1.925054\n",
      "Validation Accuracy: 41.80 %\n",
      "Epoch : 69 / 200 , Cost : 1.922268\n",
      "Validation Accuracy: 41.87 %\n",
      "Epoch : 70 / 200 , Cost : 1.919523\n",
      "Validation Accuracy: 41.92 %\n",
      "Epoch : 71 / 200 , Cost : 1.916819\n",
      "Validation Accuracy: 41.96 %\n",
      "Epoch : 72 / 200 , Cost : 1.914157\n",
      "Validation Accuracy: 41.98 %\n",
      "Epoch : 73 / 200 , Cost : 1.911536\n",
      "Validation Accuracy: 42.03 %\n",
      "Epoch : 74 / 200 , Cost : 1.908955\n",
      "Validation Accuracy: 42.04 %\n",
      "Epoch : 75 / 200 , Cost : 1.906416\n",
      "Validation Accuracy: 42.10 %\n",
      "Epoch : 76 / 200 , Cost : 1.903917\n",
      "Validation Accuracy: 42.17 %\n",
      "Epoch : 77 / 200 , Cost : 1.901458\n",
      "Validation Accuracy: 42.28 %\n",
      "Epoch : 78 / 200 , Cost : 1.899039\n",
      "Validation Accuracy: 42.36 %\n",
      "Epoch : 79 / 200 , Cost : 1.896658\n",
      "Validation Accuracy: 42.37 %\n",
      "Epoch : 80 / 200 , Cost : 1.894316\n",
      "Validation Accuracy: 42.43 %\n",
      "Epoch : 81 / 200 , Cost : 1.892013\n",
      "Validation Accuracy: 42.47 %\n",
      "Epoch : 82 / 200 , Cost : 1.889747\n",
      "Validation Accuracy: 42.54 %\n",
      "Epoch : 83 / 200 , Cost : 1.887517\n",
      "Validation Accuracy: 42.55 %\n",
      "Epoch : 84 / 200 , Cost : 1.885325\n",
      "Validation Accuracy: 42.62 %\n",
      "Epoch : 85 / 200 , Cost : 1.883168\n",
      "Validation Accuracy: 42.62 %\n",
      "Epoch : 86 / 200 , Cost : 1.881046\n",
      "Validation Accuracy: 42.65 %\n",
      "Epoch : 87 / 200 , Cost : 1.878960\n",
      "Validation Accuracy: 42.71 %\n",
      "Epoch : 88 / 200 , Cost : 1.876907\n",
      "Validation Accuracy: 42.78 %\n",
      "Epoch : 89 / 200 , Cost : 1.874888\n",
      "Validation Accuracy: 42.82 %\n",
      "Epoch : 90 / 200 , Cost : 1.872902\n",
      "Validation Accuracy: 42.86 %\n",
      "Epoch : 91 / 200 , Cost : 1.870947\n",
      "Validation Accuracy: 42.85 %\n",
      "Epoch : 92 / 200 , Cost : 1.869024\n",
      "Validation Accuracy: 42.87 %\n",
      "Epoch : 93 / 200 , Cost : 1.867132\n",
      "Validation Accuracy: 42.90 %\n",
      "Epoch : 94 / 200 , Cost : 1.865269\n",
      "Validation Accuracy: 42.93 %\n",
      "Epoch : 95 / 200 , Cost : 1.863436\n",
      "Validation Accuracy: 42.96 %\n",
      "Epoch : 96 / 200 , Cost : 1.861630\n",
      "Validation Accuracy: 43.01 %\n",
      "Epoch : 97 / 200 , Cost : 1.859852\n",
      "Validation Accuracy: 43.02 %\n",
      "Epoch : 98 / 200 , Cost : 1.858101\n",
      "Validation Accuracy: 43.06 %\n",
      "Epoch : 99 / 200 , Cost : 1.856375\n",
      "Validation Accuracy: 43.07 %\n",
      "Epoch : 100 / 200 , Cost : 1.854675\n",
      "Validation Accuracy: 43.12 %\n",
      "Epoch : 101 / 200 , Cost : 1.852999\n",
      "Validation Accuracy: 43.18 %\n",
      "Epoch : 102 / 200 , Cost : 1.851347\n",
      "Validation Accuracy: 43.19 %\n",
      "Epoch : 103 / 200 , Cost : 1.849718\n",
      "Validation Accuracy: 43.24 %\n",
      "Epoch : 104 / 200 , Cost : 1.848111\n",
      "Validation Accuracy: 43.28 %\n",
      "Epoch : 105 / 200 , Cost : 1.846526\n",
      "Validation Accuracy: 43.33 %\n",
      "Epoch : 106 / 200 , Cost : 1.844962\n",
      "Validation Accuracy: 43.37 %\n",
      "Epoch : 107 / 200 , Cost : 1.843418\n",
      "Validation Accuracy: 43.37 %\n",
      "Epoch : 108 / 200 , Cost : 1.841894\n",
      "Validation Accuracy: 43.38 %\n",
      "Epoch : 109 / 200 , Cost : 1.840390\n",
      "Validation Accuracy: 43.41 %\n",
      "Epoch : 110 / 200 , Cost : 1.838904\n",
      "Validation Accuracy: 43.44 %\n",
      "Epoch : 111 / 200 , Cost : 1.837436\n",
      "Validation Accuracy: 43.48 %\n",
      "Epoch : 112 / 200 , Cost : 1.835987\n",
      "Validation Accuracy: 43.50 %\n",
      "Epoch : 113 / 200 , Cost : 1.834554\n",
      "Validation Accuracy: 43.52 %\n",
      "Epoch : 114 / 200 , Cost : 1.833139\n",
      "Validation Accuracy: 43.54 %\n",
      "Epoch : 115 / 200 , Cost : 1.831739\n",
      "Validation Accuracy: 43.53 %\n",
      "Epoch : 116 / 200 , Cost : 1.830356\n",
      "Validation Accuracy: 43.57 %\n",
      "Epoch : 117 / 200 , Cost : 1.828989\n",
      "Validation Accuracy: 43.60 %\n",
      "Epoch : 118 / 200 , Cost : 1.827637\n",
      "Validation Accuracy: 43.62 %\n",
      "Epoch : 119 / 200 , Cost : 1.826299\n",
      "Validation Accuracy: 43.59 %\n",
      "Epoch : 120 / 200 , Cost : 1.824976\n",
      "Validation Accuracy: 43.61 %\n",
      "Epoch : 121 / 200 , Cost : 1.823668\n",
      "Validation Accuracy: 43.64 %\n",
      "Epoch : 122 / 200 , Cost : 1.822373\n",
      "Validation Accuracy: 43.66 %\n",
      "Epoch : 123 / 200 , Cost : 1.821091\n",
      "Validation Accuracy: 43.68 %\n",
      "Epoch : 124 / 200 , Cost : 1.819823\n",
      "Validation Accuracy: 43.70 %\n",
      "Epoch : 125 / 200 , Cost : 1.818567\n",
      "Validation Accuracy: 43.77 %\n",
      "Epoch : 126 / 200 , Cost : 1.817324\n",
      "Validation Accuracy: 43.79 %\n",
      "Epoch : 127 / 200 , Cost : 1.816093\n",
      "Validation Accuracy: 43.82 %\n",
      "Epoch : 128 / 200 , Cost : 1.814874\n",
      "Validation Accuracy: 43.84 %\n",
      "Epoch : 129 / 200 , Cost : 1.813666\n",
      "Validation Accuracy: 43.84 %\n",
      "Epoch : 130 / 200 , Cost : 1.812470\n",
      "Validation Accuracy: 43.87 %\n",
      "Epoch : 131 / 200 , Cost : 1.811285\n",
      "Validation Accuracy: 43.87 %\n",
      "Epoch : 132 / 200 , Cost : 1.810111\n",
      "Validation Accuracy: 43.88 %\n",
      "Epoch : 133 / 200 , Cost : 1.808948\n",
      "Validation Accuracy: 43.87 %\n",
      "Epoch : 134 / 200 , Cost : 1.807795\n",
      "Validation Accuracy: 43.88 %\n",
      "Epoch : 135 / 200 , Cost : 1.806652\n",
      "Validation Accuracy: 43.93 %\n",
      "Epoch : 136 / 200 , Cost : 1.805520\n",
      "Validation Accuracy: 43.90 %\n",
      "Epoch : 137 / 200 , Cost : 1.804397\n",
      "Validation Accuracy: 43.94 %\n",
      "Epoch : 138 / 200 , Cost : 1.803284\n",
      "Validation Accuracy: 43.94 %\n",
      "Epoch : 139 / 200 , Cost : 1.802181\n",
      "Validation Accuracy: 43.94 %\n",
      "Epoch : 140 / 200 , Cost : 1.801086\n",
      "Validation Accuracy: 43.96 %\n",
      "Epoch : 141 / 200 , Cost : 1.800001\n",
      "Validation Accuracy: 43.97 %\n",
      "Epoch : 142 / 200 , Cost : 1.798926\n",
      "Validation Accuracy: 43.98 %\n",
      "Epoch : 143 / 200 , Cost : 1.797859\n",
      "Validation Accuracy: 44.00 %\n",
      "Epoch : 144 / 200 , Cost : 1.796801\n",
      "Validation Accuracy: 44.01 %\n",
      "Epoch : 145 / 200 , Cost : 1.795751\n",
      "Validation Accuracy: 44.02 %\n",
      "Epoch : 146 / 200 , Cost : 1.794710\n",
      "Validation Accuracy: 44.02 %\n",
      "Epoch : 147 / 200 , Cost : 1.793678\n",
      "Validation Accuracy: 44.04 %\n",
      "Epoch : 148 / 200 , Cost : 1.792654\n",
      "Validation Accuracy: 44.05 %\n",
      "Epoch : 149 / 200 , Cost : 1.791638\n",
      "Validation Accuracy: 44.07 %\n",
      "Epoch : 150 / 200 , Cost : 1.790631\n",
      "Validation Accuracy: 44.09 %\n",
      "Epoch : 151 / 200 , Cost : 1.789631\n",
      "Validation Accuracy: 44.09 %\n",
      "Epoch : 152 / 200 , Cost : 1.788640\n",
      "Validation Accuracy: 44.11 %\n",
      "Epoch : 153 / 200 , Cost : 1.787656\n",
      "Validation Accuracy: 44.14 %\n",
      "Epoch : 154 / 200 , Cost : 1.786680\n",
      "Validation Accuracy: 44.19 %\n",
      "Epoch : 155 / 200 , Cost : 1.785711\n",
      "Validation Accuracy: 44.28 %\n",
      "Epoch : 156 / 200 , Cost : 1.784751\n",
      "Validation Accuracy: 44.26 %\n",
      "Epoch : 157 / 200 , Cost : 1.783797\n",
      "Validation Accuracy: 44.28 %\n",
      "Epoch : 158 / 200 , Cost : 1.782852\n",
      "Validation Accuracy: 44.31 %\n",
      "Epoch : 159 / 200 , Cost : 1.781913\n",
      "Validation Accuracy: 44.29 %\n",
      "Epoch : 160 / 200 , Cost : 1.780982\n",
      "Validation Accuracy: 44.31 %\n",
      "Epoch : 161 / 200 , Cost : 1.780058\n",
      "Validation Accuracy: 44.32 %\n",
      "Epoch : 162 / 200 , Cost : 1.779141\n",
      "Validation Accuracy: 44.32 %\n",
      "Epoch : 163 / 200 , Cost : 1.778231\n",
      "Validation Accuracy: 44.32 %\n",
      "Epoch : 164 / 200 , Cost : 1.777329\n",
      "Validation Accuracy: 44.33 %\n",
      "Epoch : 165 / 200 , Cost : 1.776433\n",
      "Validation Accuracy: 44.34 %\n",
      "Epoch : 166 / 200 , Cost : 1.775544\n",
      "Validation Accuracy: 44.37 %\n",
      "Epoch : 167 / 200 , Cost : 1.774662\n",
      "Validation Accuracy: 44.38 %\n",
      "Epoch : 168 / 200 , Cost : 1.773787\n",
      "Validation Accuracy: 44.40 %\n",
      "Epoch : 169 / 200 , Cost : 1.772918\n",
      "Validation Accuracy: 44.42 %\n",
      "Epoch : 170 / 200 , Cost : 1.772057\n",
      "Validation Accuracy: 44.45 %\n",
      "Epoch : 171 / 200 , Cost : 1.771202\n",
      "Validation Accuracy: 44.46 %\n",
      "Epoch : 172 / 200 , Cost : 1.770353\n",
      "Validation Accuracy: 44.47 %\n",
      "Epoch : 173 / 200 , Cost : 1.769511\n",
      "Validation Accuracy: 44.48 %\n",
      "Epoch : 174 / 200 , Cost : 1.768676\n",
      "Validation Accuracy: 44.48 %\n",
      "Epoch : 175 / 200 , Cost : 1.767847\n",
      "Validation Accuracy: 44.49 %\n",
      "Epoch : 176 / 200 , Cost : 1.767024\n",
      "Validation Accuracy: 44.48 %\n",
      "Epoch : 177 / 200 , Cost : 1.766208\n",
      "Validation Accuracy: 44.49 %\n",
      "Epoch : 178 / 200 , Cost : 1.765398\n",
      "Validation Accuracy: 44.52 %\n",
      "Epoch : 179 / 200 , Cost : 1.764594\n",
      "Validation Accuracy: 44.53 %\n",
      "Epoch : 180 / 200 , Cost : 1.763797\n",
      "Validation Accuracy: 44.54 %\n",
      "Epoch : 181 / 200 , Cost : 1.763006\n",
      "Validation Accuracy: 44.56 %\n",
      "Epoch : 182 / 200 , Cost : 1.762221\n",
      "Validation Accuracy: 44.55 %\n",
      "Epoch : 183 / 200 , Cost : 1.761442\n",
      "Validation Accuracy: 44.55 %\n",
      "Epoch : 184 / 200 , Cost : 1.760669\n",
      "Validation Accuracy: 44.55 %\n",
      "Epoch : 185 / 200 , Cost : 1.759902\n",
      "Validation Accuracy: 44.56 %\n",
      "Epoch : 186 / 200 , Cost : 1.759141\n",
      "Validation Accuracy: 44.56 %\n",
      "Epoch : 187 / 200 , Cost : 1.758386\n",
      "Validation Accuracy: 44.61 %\n",
      "Epoch : 188 / 200 , Cost : 1.757637\n",
      "Validation Accuracy: 44.61 %\n",
      "Epoch : 189 / 200 , Cost : 1.756893\n",
      "Validation Accuracy: 44.64 %\n",
      "Epoch : 190 / 200 , Cost : 1.756156\n",
      "Validation Accuracy: 44.62 %\n",
      "Epoch : 191 / 200 , Cost : 1.755424\n",
      "Validation Accuracy: 44.64 %\n",
      "Epoch : 192 / 200 , Cost : 1.754698\n",
      "Validation Accuracy: 44.67 %\n",
      "Epoch : 193 / 200 , Cost : 1.753977\n",
      "Validation Accuracy: 44.69 %\n",
      "Epoch : 194 / 200 , Cost : 1.753262\n",
      "Validation Accuracy: 44.70 %\n",
      "Epoch : 195 / 200 , Cost : 1.752552\n",
      "Validation Accuracy: 44.69 %\n",
      "Epoch : 196 / 200 , Cost : 1.751848\n",
      "Validation Accuracy: 44.71 %\n",
      "Epoch : 197 / 200 , Cost : 1.751149\n",
      "Validation Accuracy: 44.72 %\n",
      "Epoch : 198 / 200 , Cost : 1.750456\n",
      "Validation Accuracy: 44.73 %\n",
      "Epoch : 199 / 200 , Cost : 1.749768\n",
      "Validation Accuracy: 44.76 %\n",
      "Epoch : 200 / 200 , Cost : 1.749085\n",
      "Validation Accuracy: 44.78 %\n",
      "The model has been trained successfully.\n"
     ]
    }
   ],
   "source": [
    "# Train the RNN(lstm) network.\n",
    "# In this tutorial, we will run only 20 epochs.\n",
    "rnn_net.trainRNN(train_input,train_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested with 1650 datasets.\n",
      "Test Accuracy: 47.74 %\n"
     ]
    }
   ],
   "source": [
    "# Test the trained RNN(lstm) network.\n",
    "rnn_net.testRNN(test_input,test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable list as a dictionary format.\n",
      ">> weight, bias, y_hat, optimizer, cost\n",
      "\n",
      "Simple RNN training session is terminated.\n"
     ]
    }
   ],
   "source": [
    "# Save the trained parameters.\n",
    "vars = rnn_net.getVariables()\n",
    "# Terminate the session.\n",
    "rnn_net.closeRNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN(LSTM) Training\n",
    "- Epoch는 50, 100, 200으로 총 3번에 걸쳐 실행하였으며, 자세한 설정사항은 아래와 같다.\n",
    "- 설정값\n",
    " 1. 훈련에 사용된 데이터: 8,500 * 20 * 38 (# of examples, # of time steps ,# of input features)\n",
    " 2. 테스트에 사용된 데이터 : 1,650 * 20 * 38 (# of examples, # of time steps ,# of input features)\n",
    " 3. 훈련에 사용되는 데이터중 20%를 validation 셋으로 구성하였다. (1,700개) 이 validation은 epoch가 진행됨에 따라 변화되는 accuracy(인풋 케릭터에 대한 아웃풋 케릭터 결과)를 보여준다.\n",
    " 4. parameters: epoch: 200, 1 hidden layer and its size: 200, learning rate: 0.001, cost function: adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import main.setvalues as set\n",
    "import main.rnnnetworkmodels as net\n",
    "\n",
    "# import data.\n",
    "# data directory.\n",
    "ann_data = np.load(my_absdir+'/train_data/pg8800_lstm_char_data.npz')\n",
    "train_input = ann_data['train_input']\n",
    "train_output = ann_data['train_output']\n",
    "test_input = ann_data['test_input']\n",
    "test_output = ann_data['test_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "problem = 'classification' # classification, regression\n",
    "rnnCell = 'lstm' # rnn, lstm\n",
    "trainEpoch = 50\n",
    "learningRate = 0.001\n",
    "learningRateDecay = 'off' # on, off\n",
    "batchSize = 100\n",
    "hiddenLayers = [200]\n",
    "timeStep = 20\n",
    "costFunction = 'adam' # gradient, adam\n",
    "validationCheck = 'on' # if validationCheck is on, then 20% of train data will be taken for validation.\n",
    "\n",
    "lstm_values = set.simpleRNNParam(inputData=train_input,\n",
    "                           targetData=train_output,\n",
    "                           timeStep=timeStep,\n",
    "                           hiddenUnits=hiddenLayers\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setting hidden layers: weightMatrix and biasMatrix\n",
    "lstm_weightMatrix = lstm_values.genWeight()\n",
    "lstm_biasMatrix = lstm_values.genBias()\n",
    "lstm_input_x,lstm_input_y = lstm_values.genSymbol()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lstm_net = net.simpleRNNModel(inputSymbol=lstm_input_x,\n",
    "                               outputSymbol=lstm_input_y,\n",
    "                               rnnCell=rnnCell,\n",
    "                               problem=problem,\n",
    "                               trainEpoch=trainEpoch,\n",
    "                               learningRate=learningRate,\n",
    "                               timeStep=timeStep,\n",
    "                               batchSize=batchSize,\n",
    "                               validationCheck=validationCheck,\n",
    "                               weightMatrix=lstm_weightMatrix,\n",
    "                               biasMatrix=lstm_biasMatrix)\n",
    "\n",
    "# Generate a RNN(lstm) network.\n",
    "lstm_net.genRNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train the RNN(lstm) network.\n",
    "# In this tutorial, we will run only 20 epochs.\n",
    "lstm_net.trainRNN(train_input,train_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test the trained RNN(lstm) network.\n",
    "lstm_net.testRNN(test_input,test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the trained parameters.\n",
    "vars = lstm_net.getVariables()\n",
    "# Terminate the session.\n",
    "lstm_net.closeRNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result\n",
    "위 코드상에서 실험은 히든레이어 유닛 개수가 200개인경우만 한정지어 진행하였으나, 실제로는 히든레이어 유닛 개수를 50, 100, 200으로 달리하여 진행하였으며 그에 따른 결과는 다음과 같다. \n",
    "1. 히든레이어 개수와 상관없이 훈련이 안되던 ANN의 결과와 비교해 볼 때, RNN(Vanilla)와 RNN(LSTM)은 성능 향상을 보여주고 있다. \n",
    "2. 하지만 RNN(Vanilla)와 RNN(LSTM)을 놓고 비교해볼 경우 RNN(LSTM)이 RNN(Vanilla)보다 더 좋은 훈련 성능을 보여주고 있다. \n",
    "\n",
    "\n",
    "\n",
    "|       Model    | Hidden Units  | Accuracy     |\n",
    "| :------------: | :-----------: | -----------: |\n",
    "| RNN(Vanilla)   |       50      |     %   |\n",
    "| RNN(Vanilla)   |       100     |     47.74%   |\n",
    "| RNN(Vanilla)   |       200     |     49.89%   |\n",
    "| RNN(LSTM)      |       50      |     49.76%   |\n",
    "| RNN(LSTM)      |       100     |     56.54%   |\n",
    "| RNN(LSTM)      |       200     |     **72.59%**   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Experiment.\n",
    "1. word 단위의 데이터를 준비하고 실험해보자.\n",
    "2. 데이터 준비 방법 2를 통해 데이터셋을 정제하고 ANN에서 재실험을 해보자.\n",
    "3. 전통적인 방식의 RNN-cell과 LSTM-cell 두 종류를 이용한 RNN의 성능 비교를 해보자.\n",
    "\n",
    "### Github Code\n",
    "Go to the following github and find reports folder. You can run char_ANN_LSTM.py for duplicating the experiment.\n",
    "https://github.com/hyung8758/HY_python_NN.git\n",
    "\n",
    "### Reference\n",
    "\n",
    "- https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/dynamic_rnn.py\n",
    "- https://danijar.com/introduction-to-recurrent-networks-in-tensorflow/\n",
    "- https://github.com/jaekookang/useful_bits/blob/dev/Machine_Learning/RNN_LSTM/predict_character/rnn_char.ipynb\n",
    "More but I cannot remember...\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
