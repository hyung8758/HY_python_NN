{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of English character recognition performance between RNN(Vanilla) and RNN(LSTM).\n",
    "                                                                                        Hyungwon Yang\n",
    "                                                                                             04.20.17\n",
    "                                                                                            EMCS Labs\n",
    "### Task\n",
    "Tensorflow에서 제공하는 기본적인 RNN방식과 LSTM 셀을 적용한 RNN방식 두 모델의 성능을 비교한다.\n",
    "- 영어 character 단위의 데이터셋을 이용하여 훈련한 뒤, 훈련에 사용하지 않은 테스트 셋으로 결과를 추출하여 두 모델의 성능을 비교한다.\n",
    "\n",
    "### Training Corpus\n",
    "- Project Gutenberg's The Divine Comedy, Complete, by Dante Alighieri\n",
    "This eBook is for the use of anyone anywhere at no cost and with almost no restrictions whatsoever. You may copy it, give it away or re-use it under the terms of the Project Gutenberg License included with this eBook or online at www.gutenberg.org\n",
    "The part of the corpus was extracted for training.\n",
    "\n",
    "### Experimental Setting.\n",
    "- Python 3.5.3\n",
    "- Tnesorflow 1.0.0\n",
    "- Mac OSX sierra 10.12.4\n",
    "\n",
    "### Data Preprocessing.\n",
    "- 이전 report1에서 보고하였던 것으로 갈음한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN(Vanilla) Training\n",
    "- Epoch는 50, 100, 200으로 총 3번에 걸쳐 실행하였으며, 자세한 설정사항은 아래와 같다.\n",
    "- 설정값\n",
    " 1. 훈련에 사용된 데이터: 8,500 * 20 * 38 (# of examples, # of time steps ,# of input features)\n",
    " 2. 테스트에 사용된 데이터 : 1,650 * 20 * 38 (# of examples, # of time steps ,# of input features)\n",
    " 3. 훈련에 사용되는 데이터중 20%를 validation 셋으로 구성하였다. (1,700개) 이 validation은 epoch가 진행됨에 따라 변화되는 accuracy(인풋 케릭터에 대한 아웃풋 케릭터 결과)를 보여준다.\n",
    " 4. parameters: epoch: 200, 1 hidden layer and its size: 200, learning rate: 0.001, cost function: adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "# HY_python_NN absolute directory.\n",
    "my_absdir = \"/Users/hyungwonyang/Google_Drive/Python/HY_python_NN\"\n",
    "sys.path.append(my_absdir)\n",
    "\n",
    "import numpy as np\n",
    "import main.setvalues as set\n",
    "import main.rnnnetworkmodels as net\n",
    "\n",
    "# import data.\n",
    "# data directory.\n",
    "rnn_data = np.load(my_absdir+'/train_data/pg8800_lstm_char_data.npz')\n",
    "train_input = rnn_data['train_input']\n",
    "train_output = rnn_data['train_output']\n",
    "test_input = rnn_data['test_input']\n",
    "test_output = rnn_data['test_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "problem = 'classification' # classification, regression\n",
    "rnnCell = 'rnn' # rnn, lstm\n",
    "trainEpoch = 20\n",
    "learningRate = 0.001\n",
    "learningRateDecay = 'off' # on, off\n",
    "batchSize = 100\n",
    "hiddenLayers = [200]\n",
    "timeStep = 20\n",
    "costFunction = 'adam' # gradient, adam\n",
    "validationCheck = 'on' # if validationCheck is on, then 20% of train data will be taken for validation.\n",
    "\n",
    "rnn_values = set.simpleRNNParam(inputData=train_input,\n",
    "                           targetData=train_output,\n",
    "                           timeStep=timeStep,\n",
    "                           hiddenUnits=hiddenLayers\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setting hidden layers: weightMatrix and biasMatrix\n",
    "rnn_weightMatrix = rnn_values.genWeight()\n",
    "rnn_biasMatrix = rnn_values.genBias()\n",
    "rnn_input_x,rnn_input_y = rnn_values.genSymbol()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN cell type is rnn\n"
     ]
    }
   ],
   "source": [
    "rnn_net = net.simpleRNNModel(inputSymbol=rnn_input_x,\n",
    "                               outputSymbol=rnn_input_y,\n",
    "                               rnnCell=rnnCell,\n",
    "                               problem=problem,\n",
    "                               trainEpoch=trainEpoch,\n",
    "                               learningRate=learningRate,\n",
    "                               timeStep=timeStep,\n",
    "                               batchSize=batchSize,\n",
    "                               validationCheck=validationCheck,\n",
    "                               weightMatrix=rnn_weightMatrix,\n",
    "                               biasMatrix=rnn_biasMatrix)\n",
    "\n",
    "# Generate a RNN(lstm) network.\n",
    "rnn_net.genRNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1 / 20 , Cost : 3.004327\n",
      "Validation Accuracy: 34.67 %\n",
      "Epoch : 2 / 20 , Cost : 2.299680\n",
      "Validation Accuracy: 36.10 %\n",
      "Epoch : 3 / 20 , Cost : 2.213341\n",
      "Validation Accuracy: 36.44 %\n",
      "Epoch : 4 / 20 , Cost : 2.179098\n",
      "Validation Accuracy: 36.74 %\n",
      "Epoch : 5 / 20 , Cost : 2.160582\n",
      "Validation Accuracy: 36.87 %\n",
      "Epoch : 6 / 20 , Cost : 2.149142\n",
      "Validation Accuracy: 36.90 %\n",
      "Epoch : 7 / 20 , Cost : 2.141430\n",
      "Validation Accuracy: 36.97 %\n",
      "Epoch : 8 / 20 , Cost : 2.135674\n",
      "Validation Accuracy: 36.95 %\n",
      "Epoch : 9 / 20 , Cost : 2.131341\n",
      "Validation Accuracy: 36.89 %\n",
      "Epoch : 10 / 20 , Cost : 2.127995\n",
      "Validation Accuracy: 36.90 %\n",
      "Epoch : 11 / 20 , Cost : 2.125090\n",
      "Validation Accuracy: 36.89 %\n",
      "Epoch : 12 / 20 , Cost : 2.122569\n",
      "Validation Accuracy: 36.96 %\n",
      "Epoch : 13 / 20 , Cost : 2.120447\n",
      "Validation Accuracy: 36.89 %\n",
      "Epoch : 14 / 20 , Cost : 2.118592\n",
      "Validation Accuracy: 36.81 %\n",
      "Epoch : 15 / 20 , Cost : 2.116935\n",
      "Validation Accuracy: 36.85 %\n",
      "Epoch : 16 / 20 , Cost : 2.115445\n",
      "Validation Accuracy: 36.84 %\n",
      "Epoch : 17 / 20 , Cost : 2.114095\n",
      "Validation Accuracy: 36.82 %\n",
      "Epoch : 18 / 20 , Cost : 2.112861\n",
      "Validation Accuracy: 36.84 %\n",
      "Epoch : 19 / 20 , Cost : 2.111722\n",
      "Validation Accuracy: 36.81 %\n",
      "Epoch : 20 / 20 , Cost : 2.110661\n",
      "Validation Accuracy: 36.79 %\n",
      "The model has been trained successfully.\n"
     ]
    }
   ],
   "source": [
    "# Train the RNN(lstm) network.\n",
    "# In this tutorial, we will run only 20 epochs.\n",
    "rnn_net.trainRNN(train_input,train_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested with 1650 datasets.\n",
      "Test Accuracy: 37.31 %\n"
     ]
    }
   ],
   "source": [
    "# Test the trained RNN(lstm) network.\n",
    "rnn_net.testRNN(test_input,test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable list as a dictionary format.\n",
      ">> weight, bias, y_hat, optimizer, cost\n",
      "\n",
      "Simple RNN training session is terminated.\n"
     ]
    }
   ],
   "source": [
    "# Save the trained parameters.\n",
    "vars = rnn_net.getVariables()\n",
    "# Terminate the session.\n",
    "rnn_net.closeRNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN(LSTM) Training\n",
    "- Epoch는 50, 100, 200으로 총 3번에 걸쳐 실행하였으며, 자세한 설정사항은 아래와 같다.\n",
    "- 설정값\n",
    " 1. 훈련에 사용된 데이터: 8,500 * 20 * 38 (# of examples, # of time steps ,# of input features)\n",
    " 2. 테스트에 사용된 데이터 : 1,650 * 20 * 38 (# of examples, # of time steps ,# of input features)\n",
    " 3. 훈련에 사용되는 데이터중 20%를 validation 셋으로 구성하였다. (1,700개) 이 validation은 epoch가 진행됨에 따라 변화되는 accuracy(인풋 케릭터에 대한 아웃풋 케릭터 결과)를 보여준다.\n",
    " 4. parameters: epoch: 200, 1 hidden layer and its size: 200, learning rate: 0.001, cost function: adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import main.setvalues as set\n",
    "import main.rnnnetworkmodels as net\n",
    "\n",
    "# import data.\n",
    "# data directory.\n",
    "ann_data = np.load(my_absdir+'/train_data/pg8800_lstm_char_data.npz')\n",
    "train_input = ann_data['train_input']\n",
    "train_output = ann_data['train_output']\n",
    "test_input = ann_data['test_input']\n",
    "test_output = ann_data['test_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "problem = 'classification' # classification, regression\n",
    "rnnCell = 'lstm' # rnn, lstm\n",
    "trainEpoch = 20\n",
    "learningRate = 0.001\n",
    "learningRateDecay = 'off' # on, off\n",
    "batchSize = 100\n",
    "hiddenLayers = [200]\n",
    "timeStep = 20\n",
    "costFunction = 'adam' # gradient, adam\n",
    "validationCheck = 'on' # if validationCheck is on, then 20% of train data will be taken for validation.\n",
    "\n",
    "lstm_values = set.simpleRNNParam(inputData=train_input,\n",
    "                           targetData=train_output,\n",
    "                           timeStep=timeStep,\n",
    "                           hiddenUnits=hiddenLayers\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setting hidden layers: weightMatrix and biasMatrix\n",
    "lstm_weightMatrix = lstm_values.genWeight()\n",
    "lstm_biasMatrix = lstm_values.genBias()\n",
    "lstm_input_x,lstm_input_y = lstm_values.genSymbol()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN cell type is lstm\n"
     ]
    }
   ],
   "source": [
    "lstm_net = net.simpleRNNModel(inputSymbol=lstm_input_x,\n",
    "                               outputSymbol=lstm_input_y,\n",
    "                               rnnCell=rnnCell,\n",
    "                               problem=problem,\n",
    "                               trainEpoch=trainEpoch,\n",
    "                               learningRate=learningRate,\n",
    "                               timeStep=timeStep,\n",
    "                               batchSize=batchSize,\n",
    "                               validationCheck=validationCheck,\n",
    "                               weightMatrix=lstm_weightMatrix,\n",
    "                               biasMatrix=lstm_biasMatrix)\n",
    "\n",
    "# Generate a RNN(lstm) network.\n",
    "lstm_net.genRNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1 / 20 , Cost : 2.945145\n",
      "Validation Accuracy: 29.73 %\n",
      "Epoch : 2 / 20 , Cost : 2.457450\n",
      "Validation Accuracy: 33.45 %\n",
      "Epoch : 3 / 20 , Cost : 2.300332\n",
      "Validation Accuracy: 35.29 %\n",
      "Epoch : 4 / 20 , Cost : 2.228929\n",
      "Validation Accuracy: 36.03 %\n",
      "Epoch : 5 / 20 , Cost : 2.182124\n",
      "Validation Accuracy: 37.01 %\n",
      "Epoch : 6 / 20 , Cost : 2.143274\n",
      "Validation Accuracy: 37.69 %\n",
      "Epoch : 7 / 20 , Cost : 2.106803\n",
      "Validation Accuracy: 38.43 %\n",
      "Epoch : 8 / 20 , Cost : 2.072101\n",
      "Validation Accuracy: 39.16 %\n",
      "Epoch : 9 / 20 , Cost : 2.040219\n",
      "Validation Accuracy: 39.87 %\n",
      "Epoch : 10 / 20 , Cost : 2.011420\n",
      "Validation Accuracy: 40.53 %\n",
      "Epoch : 11 / 20 , Cost : 1.985421\n",
      "Validation Accuracy: 41.08 %\n",
      "Epoch : 12 / 20 , Cost : 1.961733\n",
      "Validation Accuracy: 41.47 %\n",
      "Epoch : 13 / 20 , Cost : 1.939799\n",
      "Validation Accuracy: 41.84 %\n",
      "Epoch : 14 / 20 , Cost : 1.919247\n",
      "Validation Accuracy: 42.21 %\n",
      "Epoch : 15 / 20 , Cost : 1.899938\n",
      "Validation Accuracy: 42.59 %\n",
      "Epoch : 16 / 20 , Cost : 1.881887\n",
      "Validation Accuracy: 42.89 %\n",
      "Epoch : 17 / 20 , Cost : 1.864916\n",
      "Validation Accuracy: 43.19 %\n",
      "Epoch : 18 / 20 , Cost : 1.848842\n",
      "Validation Accuracy: 43.47 %\n",
      "Epoch : 19 / 20 , Cost : 1.833539\n",
      "Validation Accuracy: 43.67 %\n",
      "Epoch : 20 / 20 , Cost : 1.818909\n",
      "Validation Accuracy: 43.91 %\n",
      "The model has been trained successfully.\n"
     ]
    }
   ],
   "source": [
    "# Train the RNN(lstm) network.\n",
    "# In this tutorial, we will run only 20 epochs.\n",
    "lstm_net.trainRNN(train_input,train_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested with 1650 datasets.\n",
      "Test Accuracy: 45.98 %\n"
     ]
    }
   ],
   "source": [
    "# Test the trained RNN(lstm) network.\n",
    "lstm_net.testRNN(test_input,test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable list as a dictionary format.\n",
      ">> weight, bias, y_hat, optimizer, cost\n",
      "\n",
      "Simple RNN training session is terminated.\n"
     ]
    }
   ],
   "source": [
    "# Save the trained parameters.\n",
    "vars = lstm_net.getVariables()\n",
    "# Terminate the session.\n",
    "lstm_net.closeRNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result\n",
    "위 코드상에서 실험은 히든레이어 유닛 개수가 200개인경우만 한정지어 진행하였으나, 실제로는 히든레이어 유닛 개수를 50, 100, 200으로 달리하여 진행하였으며 그에 따른 결과는 다음과 같다. \n",
    "1. 히든레이어 개수와 상관없이 훈련이 안되던 ANN의 결과와 비교해 볼 때, RNN(Vanilla)와 RNN(LSTM)은 성능 향상을 보여주고 있다. \n",
    "2. 하지만 RNN(Vanilla)와 RNN(LSTM)을 놓고 비교해볼 경우 RNN(LSTM)이 RNN(Vanilla)보다 더 좋은 훈련 성능을 보여주고 있다. 두 모델의 히든레이어 개수가 200일 경우, RNN(Vanilla)의 정확도는 50.23%이고 RNN(LSTM)은 72.59로 후자가 대략 22%정도의 월등한 성능차를 보여주고 있다. \n",
    "3. 또한 Accuracy 측면에서 RNN(Vanilla)는 불안정하게 하향과 상향을 반복하는 반면, RNN(LSTM)은 비교적 안정된 상향을 보여주고 있다.\n",
    "4. 따라서 character를 훈련할 때, RNN(LSTM)이 RNN(Vanilla)보다 더 좋은 성능을 보여준다는 것을 본 실험을 통해 증명되었다.\n",
    "\n",
    "\n",
    "\n",
    "|       Model    | Hidden Units  | Accuracy     |\n",
    "| :------------: | :-----------: | -----------: |\n",
    "| RNN(Vanilla)   |       50      |     44.42%   |\n",
    "| RNN(Vanilla)   |       100     |     47.86%   |\n",
    "| RNN(Vanilla)   |       200     |     **50.23%**   |\n",
    "| RNN(LSTM)      |       50      |     49.76%   |\n",
    "| RNN(LSTM)      |       100     |     56.54%   |\n",
    "| RNN(LSTM)      |       200     |     **72.59%**   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Github Code\n",
    "다음의 깃헙 코드를 다운받으면 본 실험을 재현할 수 있다.\n",
    "- https://github.com/hyung8758/HY_python_NN.git\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
